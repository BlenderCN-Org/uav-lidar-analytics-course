<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>GIS595-004/603; MEA592-006/601:<br>UAS Mapping for 3D Modeling</title>

<link rel="shortcut icon" href=".././img/favicon.ico" />

<link href="../layout.css" rel="stylesheet" type="text/css" media="screen">
<link href="../style.css" rel="stylesheet" type="text/css" media="screen">

</head>

<body>

<div id="outercontainer">
<div id="container">

<header>
<div id="header-image">
    <h1>GIS595-004/603; MEA592-006/601:<br>UAS Mapping for 3D Modeling</h1>
</div>

<nav>
<ul class="nav">
<li><a href="../index.html">Syllabus</a></li>
<li><a href="../schedule.html">Schedule</a></li>
<li><a href="../logistics.html">Course logistics</a></li>
<li><a href="../topics.html">Topics</a></li>
<!--<li><a href="../lectures.html">Lectures</a></li>-->
<li><a href="../projects.html">Projects</a></li>
<li><a href="../workshop.html">Workshop</a></li>
</ul>
</nav>

</header>

<main>
<!-- This is a generated file. Do not edit. -->
<h2>Processing of UAS imagery in OpenDroneMap</h2>

We will reconstruct DSM and create orthophoto in <a href="http://opendronemap.github.io/odm/">
OpenDroneMap</a> - open source toolkit for processing civilian drone imagery.
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/0UctfoeNB_Y" frameborder="0" allowfullscreen></iframe>

<h3>Setting up Docker and directory structure</h3>

We will run OpenDroneMap using Docker to simplify setup (the internally used operating system is Ubuntu).
OpenDroneMap doesn't have a desktop GUI, we will run it in command line,
which is quite simple once we deal with preprocessing.
We will use Ubuntu VCL (Ubuntu 16.04 LTS).
Once you launch it:

<ol>

<li>Download and install <a href="https://www.docker.com/">Docker</a>. See
    <a href="https://ncsu-geoforall-lab.github.io/open-science-course/topics/environments.html">an open science class instructions</a>
    for introduction to Docker and recommended download links.
</li>

<li>Either in file manager or in command line create a directory
    called <code>odm</code>. Put it somewhere with enough disk space (home folder).
    Inside the <code>odm</code> directory create directories
    <code>images</code>, <code>orthophoto</code>,
    <code>georeferencing</code>, and <code>texturing</code>.
    On unix-like systems, creating the directories would look something
    like this:
<pre><code>cd
mkdir odm
cd odm
mkdir images
mkdir orthophoto
mkdir georeferencing
mkdir texturing
</code></pre>
</li>

<li>Get your data ready:
    Download the <a href="https://drive.google.com/open?id=0B1AfQGDB8tPXfnlzUkpqcGl3V2ZMeTQ2VmJUeTFkNXJ6al83UGJJR2VXaVRRUWRIVWpHZDg">photos and log</a>
    for the class. Unzip them. Move the images and all the other files
    to the <code>images</code> directory (no subdirectories).
    On unix-like systems, moving of the files would look something like
    this:
<pre><code>mv unzipped-dir/* images/
</code></pre>
</li>
<li>
    We will run ODM through Docker. We will download a pre-built image of OpenDroneMap
    (this will take some time):
<pre><code>docker pull opendronemap/opendronemap
</code></pre>
</li>
</ol>

<h3>Preprocesing of images</h3>
Before we can run OpenDroneMap, we need to preprocess the images.
OpenDroneMap takes GPS position and focal length from images, not from the log.
Since the images don't have this information in their
<a href="https://en.wikipedia.org/wiki/Exif">EXIF data</a>, we will have
to add them there.
<ol>
    <li>First, we will need to convert the <code>.jxl</code> log
file into a CSV file using
<a href="https://github.com/wenzeslaus/jxl2csv">Vashek's script jxl2csv</a>.
<pre><code><span class="comment"># change directory to folder with images
</span>cd ~/odm/images
<span class="comment"># download the script
</span>wget https://raw.githubusercontent.com/wenzeslaus/jxl2csv/master/jxl2csv.py
<span class="comment"># run the script - full.jxl is input, full.csv is output
</span>python jxl2csv.py full.jxl full.csv
<span class="comment"># convert uppercase file names to lowercase to match the JPG files
</span>head full.csv
tr A-Z a-z &lt; full.csv &gt; full_lowercase.csv
head full_lowercase.csv
</code></pre>
</li>
    <li>Then we need to upload the focal length and GPS into the photos' EXIF data,
because our photos don't have this information in EXIF. We will use
<a href="https://github.com/petrasovaa/write-EXIF-GPS">Anna's script</a>
for that. There will be some warnings about missing files and truncating the
entry, ignore them.
Warning: script <code>write_exif_GPS.py</code> is not general, focal length and camera model are hardcoded
and must be changed for different cameras.
<pre><code><span class="comment"># download the script
</span>wget https://raw.githubusercontent.com/petrasovaa/write-EXIF-GPS/master/write_exif_GPS.py
<span class="comment"># install libraries the script requires
</span>sudo apt update &amp;&amp; apt install -y proj-bin exiv2
<span class="comment"># run the script, input is the CSV we created from jxl file
</span>python write_exif_GPS.py full_lowercase.csv
</code></pre>

</li>

    <li>Finally, we will need to identify GCPs in the images.
    To georeference the DSM, we need to prepare a text file with each GCP on one line,
    where the numbers represent GCP X, GCP Y, GCP altitude, image column, image row, image name.
    For example:
<pre><code>636795.964 219156.17 105.06 1588 2066 dsc01861.jpg
</code></pre>
    Download the <a href="./resources/gcp_odm.txt">prepared GCP file here</a>.
    This file was manually prepared by identifying the GCPs on selected images.
<pre><code>wget http://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/assignments/resources/gcp_odm.txt
</code></pre>
    </li>
</ol>

Now we are ready to run OpenDroneMap!

<h3>Running OpenDroneMap</h3>

We will use default parameters. To review parameters run:
<pre><code>docker run -it --rm opendronemap/opendronemap --help
</code></pre>

Now we launch the computation. We will keep default values, but we need to specify the path to file with GCPs.
Some explanation of the <code>docker run</code> command:
<ul>
    <li><code>-v</code> links our directory <code>images</code> to
    a directory inside Docker container</li>
    <li>The string <code>$(pwd)</code> in the commands stands for the current
    working directory which should be the <code>odm</code> directory
    we created earlier.</li>
</ul>

<pre><code>cd ~/odm
docker run -it --rm -v $(pwd)/images:/code/images -v $(pwd)/orthophoto:/code/odm_orthophoto -v $(pwd)/georeferencing:/code/odm_georeferencing -v $(pwd)/texturing:/code/odm_texturing opendronemap/opendronemap --mesh-size 100000 --resize-to 1000 --gcp /code/images/gcp_odm.txt
</code></pre>

OpenDroneMap will do the processing in parallel. However, each process
requires certain amount of memory (RAM) based on the size of input
images. If you want to limit the memory usage, you need to limit the
number of processes using the <code>--opensfm-processes</code> command
line option.

<h3>Running WebODM</h3>

Install additional packages for management of WebODM (assuming you
already have Docker up and running):

<pre><code>sudo apt install docker-compose python-setuptools python-pip
</code></pre>

Get WebODM code using Git:

<pre><code>git clone https://github.com/OpenDroneMap/WebODM --config core.autocrlf=input
</code></pre>

Go the the course code directory:

<pre><code>cd WebODM
</code></pre>

Start WebODM:

<pre><code>./webodm.sh start &amp;
</code></pre>

Now go to the URL specified in the output, it will be likely
<tt>http://localhost:8000</tt>. You will be prompted to create an
administrator account. Create it. It will be the only account we will
need for the exercise.

Upload images to the task which is already there or create a new one.
Change the resolution of images to 800 to speed up the upload and
computation (this reduces the quality of the images).

Now you need to wait for the processing to finish. To follow the
processing, you can access WebODM from outside the VCL machine. Enter
the VCL machine IP address as URL to your web browser and add
<tt>:8000</tt> to it. You should get a login page and you should be able
to log in using the admin account credentials you created earlier.

<h3>Using the results</h3>

All results are stored in the <code>odm</code> directory,
specifically in <code>orthophoto</code> and <code>georeferencing</code>
subdirectories.
We are interested in the point cloud located in the
<code>georeferencing</code> directory.
The point cloud is available as a LAS or text file.
In GRASS GIS, you can use
<a href="https://grass.osgeo.org/grass72/manuals/r.in.lidar.html">r.in.lidar</a>
module or
<a href="https://grass.osgeo.org/grass72/manuals/r.in.xyz.html">r.in.xyz</a>
module to create a DSM by binning
or <a href="https://grass.osgeo.org/grass72/manuals/v.surf.rst.html">v.surf.rst</a>
to interpolate a DSM.
The georeferenced orthophoto is a <code>.tif</code> file located in the
<code>orthophoto</code> directory.
The CRS of the point cloud and orthophoto should be in EPSG:3358
(NC State Plane Meters).

<p>
<center>
<img src="../img/opendronemap_midpines_dsm.png" style="width: 70%;">
<br>
Example resulting shaded DSM created in GRASS GIS based on a point cloud
obtained by the above process.
</center>

<p>
We can also quickly view our results in
<a href="http://plas.io/">plas.io</a> (needs browser with WebGL
support).

<p>
<center>
<img src="../img/opendronemap_midpines_point_cloud.png" style="width: 70%;">
<br>
Example resulting shaded DSM created in GRASS GIS based on a point cloud
obtained by the above process.
</center>

<p>
To view and edit the mesh stored as OBJ and located in the
<code>texturing</code> directory, we can use MeshLab.
MeshLab can also import the point cloud stored as PLY file.

</main>

<footer>

<nav>
<ul>
<li><a class="term-changes" href="https://moodle-courses1718.wolfware.ncsu.edu/course/view.php?id=4709">Moodle site</a></li>
<li><a href="http://help.ncsu.edu/">Computing Help</a></li>
<li><a href="http://geospatial.ncsu.edu/">GIST Home</a></li>
<li><a href="http://www.ncsu.edu/policies/prr-disclaimer.php">Disclaimer</a></li>
<li><a href="http://oit.ncsu.edu/itaccess">Accessibility</a></li>
<li><a href="https://github.com/ncsu-geoforall-lab/uav-lidar-analytics-course" title="Source code for web pages on GitHub">
        <img src="../img/github_logo.png" alt="GitHub Octocat logo">
    </a>
</li>
<li title="Copyright and license (not applicable to linked materials)">
    &copy; 2018
    <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a>
    <a href="http://geospatial.ncsu.edu/osgeorel/">NCSU GeoForAll Lab</a>
</li>
</ul>
</nav>

</footer>

</div>
</div>

</body>
</html>
