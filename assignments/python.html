<h2>Using Python and GRASS GIS</h2>

Outline:

<ul>
    <li>Import lidar points.
    <li>Interpolate with parallelization.
    <li>Process multiple maps at once and generate an HTML report.
    <li>Use matplotlib to show terrain profiles.
</ul>

Data:

<ul>
    <li><a href="https://drive.google.com/open?id=0B1AfQGDB8tPXfmZPRHlYSTNIZzdpRVBzay04c0VXUjM4Nzlmbjl5WDlrcGs1bFVLczlTd1k">Lake Wheeler GRASS Location</a>;
        be sure to use separate Mapset for this assignment
    <li>selected LAS tiles from
        <a href="http://fatra.cnr.ncsu.edu/lidar">here</a>
        (see below for the tiles we will need; you can use the provided
        Python code to download them)
</ul>

Tools:

<ul>
    <li>
        Your <a href="http://grass.osgeo.org">GRASS GIS 7</a>
        installation should also include <a href="http://www.liblas.org/">libLAS</a> library
        which is used by GRASS modules <em></em>v.in.lidar</em> and <em>r.in.lidar</em>
        (standalone GRASS GIS for MS Windows, OSGeo4W and Ubuntu packages contain libLAS).
    </li>
    <li>libLAS installation should include command line tool las2las.
</ul>


<h3>Downloading the data</h3>

In case you don't have the lidar tiles, download them using Python,
otherwise skip this step.

First, create a directory where you want to have the files. Then
set it as current directory in Python:

<pre><code>
# use path which applies to you
# on Windows use something like 'D:\\path\\to\\files'
os.chdir('/path/to/las/files')
</code></pre>

Then, download the files using:

<pre><code>
import urllib

base_url = 'http://fatra.cnr.ncsu.edu/lidar/'

urllib.urlretrieve(base_url + '0791_005.las', '0791_005.las')
urllib.urlretrieve(base_url + '0791_011.las', '0791_011.las')
urllib.urlretrieve(base_url + '0792_017.las', '0792_017.las')
urllib.urlretrieve(base_url + '0782_020.las', '0782_020.las')
urllib.urlretrieve(base_url + '0781_008.las', '0781_008.las')
</code></pre>

The same could be done in much smarter way using a for loop
and a list of files to download, so you can try that as well.


<h3>Working with command line tools</h3>

The LAS files are in different coordinate system, so we need to change it.

<p>
First, we check if we are in the directory with the files:

<pre><code>
print os.getcwd()
</code></pre>

If not, we change directory to where the files are:

<pre><code>
# on Windows use 'D:\\path\\to\\files'
os.chdir('/path/to/las/files')
</code></pre>

Now change to coordinate system for all files in the current directory:

<pre><code>
import os
from subprocess import call

for f in os.listdir('.'):
    if f.endswith('.las'):
        name, ext = os.path.splitext(f)
        call(['las2las', '--a_srs=EPSG:2264', '--t_srs=EPSG:3358', '-i',
              f, '-o', name + '_spm' + ext])
</code></pre>

In the same step, we could do also some other conversions which are
supported by las2las, for example format conversion.


<h3>Import multiple LAS files to GRASS GIS and merging them</h3>

We are looping through the lidar files
and importing points only in our region of interest.
First set the region in command line:

<pre class="other-code"><code>
g.region n=219637 s=219254 w=636730 e=637193 -p
</code></pre>

Now run this script (assuming you are in the directory with the las files):

<pre><code>
import os
import grass.script as gscript

region = gscript.region()

vectors = []
for lidar_file in os.listdir('.'):
    if lidar_file.endswith('_spm.las'):
        bbox = gscript.read_command('r.in.lidar', input=lidar_file,
                                    output='foo', flags='g').strip()
        bbox = gscript.parse_key_val(bbox, vsep=' ', val_type=float)
        if (bbox['n'] &lt; region['s'] or bbox['s'] &gt; region['n']
          or bbox['e'] &lt; region['w'] or bbox['w'] &gt; region['e']):
            gscript.info('Skipping tile %s' % lidar_file)
            continue
        name = 'tile_' + lidar_file.rsplit('.', 1)[0]
        vectors.append(name)
        gscript.run_command('v.in.lidar', input=lidar_file, output=name,
                            flags='rt', class_filter=2)
gscript.run_command('v.patch', input=vectors, output='merged_points',
                    flags='b', overwrite=True)
gscript.run_command('g.remove', type='vector', name=vectors, flags='f')
</code></pre>

In case you are having problems with projections but you know that the
projections in fact match, add <code>o</code> flag to <em>r.in.lidar</em>
and <em>v.in.lidar</em> calls.


<h3>DSM interpolation with parallelization</h3>

We will interpolate DEM using
<a href="https://grass.osgeo.org/grass70/manuals/libpython/pygrass.modules.grid.html#module-pygrass.modules.grid.grid">GridModule</a>
which allows to run <em>v.surf.rst</em>
in parallel by splitting the region into tiles and interpolating each part
and then patching them back.
First we set the region of our area
(in this example, we use very low resolution to make the computation fast):

<pre class="other-code"><code>
g.region n=219637 s=219254 w=636730 e=637193 res=1 -p
</code></pre>

Note: You need to change the visible Mapsets to something else than
the default (current Mapset and PERMANENT Mapset).
Set the visible Mapsets (SEARCH_PATH) by going to
<em>Settings -> GRASS working environment -> Mapset access</em>
and check one of the unchecked Mapsets.
Otherwise, you will get an error "AttributeError: 'VisibleMapset' object
has no attribute 'write'",
see ticket <a href="http://trac.osgeo.org/grass/ticket/2791">#2791</a>.

<p>
We import GridModule and compute the size of the tiles
if we want to run it on 4 cores at once:
<pre><code>
import grass.script as gscript
from grass.pygrass.modules.grid import GridModule

region = gscript.region()
width = region['cols'] / 2 + 1
height = region['rows'] / 2 + 1
</code></pre>

First try to run it in not parallel mode (debug=True) to see if it is working.
<pre><code>
grd = GridModule('v.surf.rst', debug=True, width=width, height=height,
                 overlap=10, processes=4, npmin=100,
                 input='merged_points', elevation='mid_pines_small_dem_1m',
                 tension=30, smooth=1, overwrite=True)
grd.run()
</code></pre>

<p>
Then run it in parallel (debug=False) and we can see the time needed reduced significantly:
<pre><code>
grd = GridModule('v.surf.rst', debug=False, width=width, height=height,
                 overlap=10, processes=4, npmin=100,
                 input='merged_points', elevation='mid_pines_small_dem_1m',
                 tension=30, smooth=1, overwrite=True)
grd.run()
</code></pre>


<h3>Working with large amount of maps</h3>

Set the region to fit one of the raster maps:

<pre class="other-code"><code>
g.region raster=2015_06_20_pix4d_11GCP_dsm
</code></pre>

Now we will compute difference between raster maps in a list
using nested for loops.

<pre><code>
rasters = ['2015_06_20_pix4d_11GCP_dsm', '2015_06_20_DSM_Trimble_11GCP',
           '2015_06_20_DSM_agi_11GCP']
for raster_a in rasters:
    for raster_b in rasters:
        if raster_a == raster_b:
            continue
        # create the name for the difference raster
        difference = "diff_{a}_{b}".format(a=raster_a.replace('@', '_'),
                                           b=raster_b.replace('@', '_'))
        # compute difference between the rasters using r.mapcalc
        gscript.mapcalc('{diff} = {a} - {b}'.format(
            a=raster_a, b=raster_b, diff=difference))
        # set color table to the resulting map
        gscript.run_command('r.colors', map=difference, color='differences')
</code></pre>

Before running the code again, we need to remove the created raster maps
(in the command line):

<pre class="other-code"><code>
g.remove type=raster pattern="diff_*" -f
</code></pre>


<h3 id="report">Generating a report</h3>

Using HTML and generated images, we can create a report using Python
for the analysis we have made.

<p>
First, we get a list of raster maps we are interested in. We
use <em>g.list</em> wrapper with <code>pattern</code>
option. Then we compute univariate statistics
and we also compute shaded relief for each raster map.
Finally, we render the raster map together with shaded relief using
<em>d.*</em> modules to a PNG file.
Note that we are using <em>d.shade</em> to avoid creating another
raster which would combine the original raster and its shaded relief.

<pre><code>
# get list of rasters we are interested in using a search pattern
rasters = gscript.list_strings('raster', pattern='2015_06_*')
# initialize a dictionary to hold statistics for each raster
stats = {}
# iterate through the list of rasters
for raster in rasters:
    # save univariate statistics for raster to dictionary
    stats[raster] = gscript.parse_command('r.univar', map=raster, flags='g')
    # compute shaded relief, use name of the original raster including mapset
    shaded_relief = raster.replace('@', '_') + '_shade'
    gscript.run_command('r.relief', input=raster, output=shaded_relief,
                        overwrite=True)
    gscript.run_command('r.colors', map=raster, color='elevation')
    # render the raster (geographical extent follows current region)
    gscript.run_command('d.mon', start='cairo', output=raster + '.png',
                        width=400, height=400, overwrite=True)
    gscript.run_command('d.shade', shade=shaded_relief, color=raster)
    gscript.run_command('d.mon', stop='cairo')
</code></pre>

Now, we create an HTML report from the data collected above.
We also link images created above to the HTML.

<pre><code>
# a template for an HTML report for one raster
template = """&lt;h2&gt;Raster map {name}&lt;/h2&gt;
&lt;h3&gt;Statistics&lt;/h3&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Mean&lt;/td&gt;&lt;td&gt;{mean}&lt;/td&gt;
&lt;tr&gt;&lt;td&gt;Variance&lt;/td&gt;&lt;td&gt;{var}&lt;/td&gt;
&lt;/table&gt;
&lt;h3&gt;Image&lt;/h3&gt;
&lt;img src="{name}.png"&gt;
"""

# write to a file using a template
with open('report.html', 'w') as output:
        for raster in sorted(rasters):
            stat = stats[raster]
            output.write(template.format(
                name=raster, mean=stat['mean'], var=stat['variance']))
</code></pre>

To remove the created raster maps, we can use (in the command line):

<pre class="other-code"><code>
g.remove type=raster pattern="*_shade" -f
</code></pre>


<h3>Terrain profiles</h3>

In this example, we will compare profiles from two raster maps,
2015_10_06_DSM_agi_8GCPs which is in PERMANENT Mapset and
mid_pines_lidar2013_dem which in DEM created from Mid Pines lidar tile.
You should have this raster map in some of the Mapsets you used before.
You need to make map from this Mapset accessible by adding it to
search path (SEARCH_PATH). This is done in GUI by going to
<em>Settings -> GRASS working environment -> Mapset access</em>
and by checking the Mapset there. In command line, use
<em>g.mapsets</em>. Alternatively, add at-sign and Mapset name
to the name of the map (<code>mapname@mapsetname</code>).

<p>
Compute a profile for multiple rasters and plot them in
<a href="http://matplotlib.org/">matplotlib</a>:

<pre><code>
import grass.script as gscript
import matplotlib.pyplot as plt

rasters = ['2015_10_06_DSM_agi_8GCPs', 'mid_pines_lidar2013_dem']
coordinates = [637160.446919, 219373.236976,
               637105.693795, 219392.416036,
               637072.439779, 219400.613538]
profiles = {}
distance = []
for raster in rasters:
    profile = gscript.read_command('r.profile', input=raster,
                                   coordinates=coordinates, quiet=True).strip()
    # parse output
    if not distance:
        for line in profile.splitlines():
            distance.append(float(line.split()[0]))
    profile_elev = []
    for line in profile.splitlines():
        profile_elev.append(float(line.split()[-1]))
    profiles[raster] = profile_elev

for raster in profiles:
    plt.plot(distance, profiles[raster], label=raster)
    plt.legend(loc=0)
plt.show()
</code></pre>

Compute profile statistics using NumPy:

<pre><code>
import numpy as np

stats = {}
for raster in profiles:
    profile = np.array(profiles[raster])
    maxim = np.max(profile)
    minim = np.min(profile)
    mean = np.mean(profile)
    stddev = np.std(profile)
    median = np.median(profile)
    roughness = np.std(np.diff(profile))
    stats[raster] = (minim, maxim, mean, stddev, median, roughness)
</code></pre>

And write them into a CSV file:

<pre><code>
with open('profile_stats.csv', 'w') as f:
    f.write(','.join(['name', 'minim', 'maxim', 'mean',
                      'stddev', 'median', 'roughness']))
    f.write('\n')
    for raster in profiles:
        f.write(raster + ',')
        f.write(','.join([str(i) for i in stats[raster]]))
        f.write('\n')
</code></pre>


<h3>Tasks and deliverables</h3>

<ul>
    <li>Try the provided code snippets. Modify them as you wish.
    <li>Extent the generated report by computing viewshed from a selected point.
    <li>Deliver the generated report as PDF.
        <ul>
            <li>To get the PDF, print the web page as PDF in a web browser
                (it should be also possible to copy the HTML through
                the clipboard to a word processor like LibreOffice Writer).
            <li>Alternatively, generate report in LaTeX, or another markup,
                and deliver generated PDF.
            <li>In any case, include also the source text file
                (but you don't have to include the individual images).
        </ul>
    <li>Run the script for creating profiles several times with different coordinates.
    <li>Deliver a short version of a normal report with your notes,
        observations, selected figures or screenshots.
</ul>

<hr>

The following parts are optional.


<h3>Downloading all files linked on a website</h3>

<pre><code>
import urllib
import re

# note the slash at the end
base_url = 'http://fatra.cnr.ncsu.edu/lidar/'

tile_file = 'tile_list.html'
# download the file (in one step)
urllib.urlretrieve(base_url, filename=tile_file)

# open the file and read it line by line
# we expect to get HTML with a list of filenames in the given directory
with open(tile_file) as html:
    for line in html:
        # search for the links (a tags with href attribute)
        # we expect one link per line in the HTML source code
        match = re.search(r'&lt;a href="(.*?)"&gt;', line)
        if not match:
            continue
        # get the content of the href attribute captured before
        filename = match.group(1)
        # download only files we are interested in
        if not filename.endswith('.las'):
            continue
        # we expect the link to be relative to our base URL
        urllib.urlretrieve(base_url + filename, filename=filename)
</code></pre>


<h3>Script with parameters</h3>

Putting filenames, paths, map names etc. to a script might see as an
easy option at the beginning, however later this gets hard to manage
as one needs to search for them and change them for different data
especially when one script is used with different data at the same time.

Here, we create a script which adds two numbers and prints the whole
expression including the result. It should be easy to imagine that
the parameters would be raster names and the expression would be
<em>r.mapcalc</em> expression which we could execute.

<pre><code>
import sys

if len(sys.argv) != 3:
    sys.exit("Please, provide two parameters")
a = float(sys.argv[1])
b = float(sys.argv[2])
c = a + b
print "{a} + {b} = {c}".format(a=a, b=b, c=c)
</code></pre>

When checking the number of parameters and getting the individual parameters,
remember that the first (zeroth) parameter is the name of the script
and the first parameter provided in the command line is at the position 1
in the list.
