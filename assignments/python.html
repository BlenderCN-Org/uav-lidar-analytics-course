<h2>Using Python and GRASS GIS</h2>

Outline:

<ul>
    <li>
</ul>

Data:

<ul>
    <li>
</ul>

Tools:

<ul>
    <li>
        Your <a href="http://wingrass.fsv.cvut.cz/grass70/">GRASS GIS 7</a>
        installation should also include <a href="http://www.liblas.org/">libLAS</a> library
        which is used by GRASS modules v.in.lidar and r.in.lidar
        (standalone GRASS GIS for MS Windows, OSGeo4W and Ubuntu packages contain libLAS).
    </li>
    <li>libLAS installation should include command line tools lasinfo and las2txt.
    <!-- <li>libLAS installation should also include support for LAZ (through LAZzip library). -->
    <li>Note that for merging las tiles (not necessary for this assignment) you need LASlib's lasmerge tool (part of LAStools).
</ul>


<h3>Working with command line tools</h3>

Change coordinate system of multiple LAS files:
<pre><code>
import os
from subprocess import call

# first check where are we
print os.getcwd()
# change directory to where your files are
# on Windows use 'D:\\path\\to\\files'
os.chdir('/path/to/las/files')
for f in os.listdir('.'):
    if f.endswith('.las'):
        name, ext = os.path.splitext(f)
        call(['las2las', '--a_srs=EPSG:2264', '--t_srs=EPSG:3358', '-i', f, '-o', name + '_spm' + ext])
</code></pre>


<h3>Import multiple LAS files to GRASS GIS and merging them</h3>

We are looping through the <a href="http://fatra.cnr.ncsu.edu/lidar/">lidar files</a>
and importing points only in our region of interest. First set the region in command line:

<pre style="background-color:#FFFFFF"><code>
g.region n=219637 s=219254 w=636730 e=637193 -p
</code></pre>
Now run this script (assuming you are in the directory with the las files):

<pre><code>
import os
import grass.script as gscript

region = gscript.region()

vectors = []
for lidar_file in os.listdir('.'):
    if lidar_file.endswith('_spm.las'):
        bbox = gscript.read_command('r.in.lidar', input=lidar_file, output='foo', flags='g').strip()
        bbox = gscript.parse_key_val(bbox, vsep=' ', val_type=float)
        if bbox['n'] < region['s'] or bbox['s'] > region['n'] or bbox['e'] < region['w'] or bbox['w'] > region['e']:
            gscript.info('Skipping tile %s' % lidar_file)
            continue
        name = 'tile_' + lidar_file.rsplit('.', 1)[0]
        vectors.append(name)
        gscript.run_command('v.in.lidar', input=lidar_file, output=name, flags='rt', class_filter=2)
gscript.run_command('v.patch', input=vectors, output='merged_points', flags='b', overwrite=True)
gscript.run_command('g.remove', type='vector', name=vectors, flags='f')
</code></pre>

<h3>DSM interpolation with parallelization</h3>

We will interpolate DEM using <a href="https://grass.osgeo.org/grass70/manuals/libpython/pygrass.modules.grid.html#module-pygrass.modules.grid.grid">
GridModule</a> which allows to run v.surf.rst
in parallel by splitting the region into tiles and interpolating each part
and then patching them back.
First we set the region of our area:
<pre style="background-color:#FFFFFF"><code>
g.region n=219637 s=219254 w=636730 e=637193 res=1 -p
</code></pre>

We import GridModule and compute the size of the tiles
if we want to run it on 4 cores at once:
<pre><code>
import grass.script as gscript
from grass.pygrass.modules.grid import GridModule

region = gscript.region()
width = region['cols'] / 2 + 1
height = region['rows'] / 2 + 1
</code></pre>

First try to run it in not parallel mode (debug=True) to see if it is working.
<pre><code>
grd = GridModule('v.surf.rst', debug=True, width=width, height=height, overlap=10, processes=4, input='merged_points', elevation='mid_pines_small_dem_1m', tension=30, smooth=1, overwrite=True)
grd.run()
</code></pre>

Then run it in parallel (debug=False) and we can see the time needed reduced significantly:
<pre><code>
grd = GridModule('v.surf.rst', debug=False, width=width, height=height, overlap=10, processes=4, input='merged_points', elevation='mid_pines_small_dem_1m', tension=30, smooth=1, overwrite=True)
grd.run()
</code></pre>


<h3>Working with large amount of maps</h3>

Compute difference each map with each map


<h3>Report</h3>

Compute univariate statistics for each map
Compute shaded relief for each raster map
Render each map using d.* modules
Create an HTML report from the data above


<h3>Terrain profiles</h3>
Compute a profile for multiple rasters and plot them in <a href="http://matplotlib.org/">matplotlib</a>:
<pre><code>
import grass.script as gscript
import matplotlib.pyplot as plt

rasters = ['2015_10_06_DSM_agi_8GCPs', 'mid_pines_lidar2013_dem']
coordinates = [637132,219609,637059,219744]
profiles = {}
distance = []
for raster in rasters:
    profile = gscript.read_command('r.profile', input=raster, coordinates=coordinates, quiet=True).strip()
    # parse output
    if not distance:
        for line in profile.splitlines():
            distance.append(float(line.split()[0]))
    profile_elev = []
    for line in profile.splitlines():
        profile_elev.append(float(line.split()[-1]))
    profiles[raster] = profile_elev

for raster in profiles:
    plt.plot(distance, profiles[raster], label=raster)
    plt.legend(loc=0)
plt.show()
</code></pre>

Compute profile statistics using NumPy:
<pre><code>
import numpy as np

stats = {}
for raster in profiles:
    profile = np.array(profiles[raster])
    maxim = np.max(profile)
    minim = np.min(profile)
    mean = np.mean(profile)
    stddev = np.std(profile)
    median = np.median(profile)
    roughness = np.std(np.diff(profile))
    stats[raster] = (minim, maxim, mean, stddev, median, roughness)
</code></pre>
And write them into a CSV file:
<pre><code>
with open('profile_stats.csv', 'w') as f:
    f.write(','.join(['name', 'minim', 'maxim', 'mean', 'stddev', 'median', 'roughness']))
    f.write('\n')
    for raster in profiles:
        f.write(raster + ',')
        f.write(','.join([str(i) for i in stats[raster]]))
        f.write('\n')
</code></pre>

